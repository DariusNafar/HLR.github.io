% 2021

% 2020

@inproceedings{zheng-kordjamshidi-2020-srlgrn,
    title = "{SRLGRN}: Semantic Role Labeling Graph Reasoning Network",
    author = "Zheng, Chen  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.714",
    doi = "10.18653/v1/2020.emnlp-main.714",
    pages = "8881--8891",
    abstract = "This work deals with the challenge of learning and reasoning over multi-hop question answering (QA). We propose a graph reasoning network based on the semantic structure of the sentences to learn cross paragraph reasoning paths and find the supporting facts and the answer jointly. The proposed graph is a heterogeneous document-level graph that contains nodes of type sentence (question, title, and other sentences), and semantic role labeling sub-graphs per sentence that contain arguments as nodes and predicates as edges. Incorporating the argument types, the argument phrases, and the semantics of the edges originated from SRL predicates into the graph encoder helps in finding and also the explainability of the reasoning paths. Our proposed approach shows competitive performance on the HotpotQA distractor setting benchmark compared to the recent state-of-the-art models.",
}

@inproceedings{guo2020inference,
   Author = {Quan Guo and Hossein Rajaby Faghihi and Yue Zhang and Andrzej Uszok and Parisa Kordjamshidi},
   Title = {Inference-Masked Loss for Deep Structured Output Learning},
   Booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI 2020)},
   Year = {2020}
}

@inproceedings{zheng-etal-2020-cross,
    title = "Cross-Modality Relevance for Reasoning on Language and Vision",
    author = "Zheng, Chen  and
      Guo, Quan  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.683",
    doi = "10.18653/v1/2020.acl-main.683",
    pages = "7642--7651",
    abstract = "This work deals with the challenge of learning and reasoning over language and vision data for the related downstream tasks such as visual question answering (VQA) and natural language for visual reasoning (NLVR). We design a novel cross-modality relevance module that is used in an end-to-end framework to learn the relevance representation between components of various input modalities under the supervision of a target task, which is more generalizable to unobserved data compared to merely reshaping the original representation space. In addition to modeling the relevance between the textual entities and visual entities, we model the higher-order relevance between entity relations in the text and object relations in the image. Our proposed approach shows competitive performance on two different language and vision tasks using public benchmarks and improves the state-of-the-art published results. The learned alignments of input spaces and their relevance representations by NLVR task boost the training efficiency of VQA task.",
}

@inproceedings{dan-etal-2020-spatial,
    title = "From Spatial Relations to Spatial Configurations",
    author = "Dan, Soham  and
      Kordjamshidi, Parisa  and
      Bonn, Julia  and
      Bhatia, Archna  and
      Cai, Zheng  and
      Palmer, Martha  and
      Roth, Dan",
    booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://www.aclweb.org/anthology/2020.lrec-1.717",
    pages = "5855--5864",
    abstract = "Spatial Reasoning from language is essential for natural language understanding. Supporting it requires a representation scheme that can capture spatial phenomena encountered in language as well as in images and videos.Existing spatial representations are not sufficient for describing spatial configurations used in complex tasks. This paper extends the capabilities of existing spatial representation languages and increases coverage of the semantic aspects that are needed to ground spatial meaning of natural language text in the world. Our spatial relation language is able to represent a large, comprehensive set of spatial concepts crucial for reasoning and is designed to support composition of static and dynamic spatial configurations. We integrate this language with the Abstract Meaning Representation (AMR) annotation schema and present a corpus annotated by this extended AMR. To exhibit the applicability of our representation scheme, we annotate text taken from diverse datasets and show how we extend the capabilities of existing spatial representation languages with fine-grained decomposition of semantics and blend it seamlessly with AMRs of sentences and discourse representations as a whole.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{rajaby-faghihi-etal-2020-latent,
    title = "Latent Alignment of Procedural Concepts in Multimodal Recipes",
    author = "Rajaby Faghihi, Hossein  and
      Mirzaee, Roshanak  and
      Paliwal, Sudarshan  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the First Workshop on Advances in Language and Vision Research",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.alvr-1.5",
    doi = "10.18653/v1/2020.alvr-1.5",
    pages = "26--31",
    abstract = "We propose a novel alignment mechanism to deal with procedural reasoning on a newly released multimodal QA dataset, named RecipeQA. Our model is solving the textual cloze task which is a reading comprehension on a recipe containing images and instructions. We exploit the power of attention networks, cross-modal representations, and a latent alignment space between instructions and candidate answers to solve the problem. We introduce constrained max-pooling which refines the max pooling operation on the alignment matrix to impose disjoint constraints among the outputs of the model. Our evaluation result indicates a 19{\%} improvement over the baselines.",
}

@article{Ahmadnia_Dorr_Kordjamshidi_2020,
    title={Knowledge Graphs Effectiveness in Neural Machine Translation Improvement},
    volume={21},
    url={https://journals.agh.edu.pl/csci/article/view/3701},
    DOI={10.7494/csci.2020.21.3.3701},
    abstractNote={Neural Machine Translation (NMT) systems require a massive amount of Maintaining semantic relations between words during the translation process yields more accurate target-language output from Neural Machine Translation (NMT). Although difficult to achieve from training data alone, it is possible to leverage Knowledge Graphs (KGs) to retain source-language semantic relations in the corresponding target-language translation. The core idea is to use KG entity relations as embedding constraints to improve the mapping from source to target. This paper describes two embedding constraints, both of which employ Entity Linking (EL)---assigning a unique identity to entities---to associate words in training sentences with those in the KG: (1) a monolingual embedding constraint that supports an enhanced semantic representation of the source words through access to relations between entities in a KG; and (2) a bilingual embedding constraint that forces entity relations in the source-language to be carried over to the corresponding entities in the target-language translation. The method is evaluated for English-Spanish translation exploiting Freebase as a source of knowledge. Our experimental results show that exploiting KG information not only decreases the number of unknown words in the translation but also improves translation quality.},
    number={3},
    journal={Computer Science},
    author={Ahmadnia, Benyamin and Dorr, Bonnie J. and Kordjamshidi, Parisa},
    year={2020},
    month={Sep.}
}

@proceedings{splu-2020-international,
    title = "Proceedings of the Third International Workshop on Spatial Language Understanding",
    editor = "Kordjamshidi, Parisa  and
      Bhatia, Archna  and
      Alikhani, Malihe  and
      Baldridge, Jason  and
      Bansal, Mohit  and
      Moens, Marie-Francine",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.splu-1.0",
}

@inproceedings{kordjamshidi-etal-2020-representation,
    title = "Representation, Learning and Reasoning on Spatial Language for Downstream {NLP} Tasks",
    author = "Kordjamshidi, Parisa  and
      Pustejovsky, James  and
      Moens, Marie-Francine",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-tutorials.5",
    doi = "10.18653/v1/2020.emnlp-tutorials.5",
    pages = "28--33"
}

% 2019

@article{Kordjamshidi2019DeclarativeLP,
  title={Declarative Learning-Based Programming as an Interface to AI Systems},
  author={Parisa Kordjamshidi and D. Roth and K. Kersting},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.07809}
}

@INPROCEEDINGS{8856378,
    author={Karimian, Hamid R. and Pollard, Kevin J. and Moore, Michael J. and Kordjamshidi, Parisa},
    booktitle={2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
    title={Semantic Segmentation of Microengineered Neural Tissues*},
    year={2019},
    volume={},
    number={},
    pages={955-960},
    doi={10.1109/EMBC.2019.8856378}
}


@Article{s19071486,
    AUTHOR = {Gebrehiwot, Asmamaw and Hashemi-Beni, Leila and Thompson, Gary and Kordjamshidi, Parisa and Langan, Thomas E.},
    TITLE = {Deep Convolutional Neural Network for Flood Extent Mapping Using Unmanned Aerial Vehicles Data},
    JOURNAL = {Sensors},
    VOLUME = {19},
    YEAR = {2019},
    NUMBER = {7},
    ARTICLE-NUMBER = {1486},
    URL = {https://www.mdpi.com/1424-8220/19/7/1486},
    ISSN = {1424-8220},
    ABSTRACT = {Flooding is one of the leading threats of natural disasters to human life and property, especially in densely populated urban areas. Rapid and precise extraction of the flooded areas is key to supporting emergency-response planning and providing damage assessment in both spatial and temporal measurements. Unmanned Aerial Vehicles (UAV) technology has recently been recognized as an efficient photogrammetry data acquisition platform to quickly deliver high-resolution imagery because of its cost-effectiveness, ability to fly at lower altitudes, and ability to enter a hazardous area. Different image classification methods including SVM (Support Vector Machine) have been used for flood extent mapping. In recent years, there has been a significant improvement in remote sensing image classification using Convolutional Neural Networks (CNNs). CNNs have demonstrated excellent performance on various tasks including image classification, feature extraction, and segmentation. CNNs can learn features automatically from large datasets through the organization of multi-layers of neurons and have the ability to implement nonlinear decision functions. This study investigates the potential of CNN approaches to extract flooded areas from UAV imagery. A VGG-based fully convolutional network (FCN-16s) was used in this research. The model was fine-tuned and a k-fold cross-validation was applied to estimate the performance of the model on the new UAV imagery dataset. This approach allowed FCN-16s to be trained on the datasets that contained only one hundred training samples, and resulted in a highly accurate classification. Confusion matrix was calculated to estimate the accuracy of the proposed method. The image segmentation results obtained from FCN-16s were compared from the results obtained from FCN-8s, FCN-32s and SVMs. Experimental results showed that the FCNs could extract flooded areas precisely from UAV images compared to the traditional classifiers such as SVMs. The classification accuracy achieved by FCN-16s, FCN-8s, FCN-32s, and SVM for the water class was 97.52%, 97.8%, 94.20% and 89%, respectively.},
    DOI = {10.3390/s19071486}
}

% 2018

@inproceedings{ijcai2018-771,
  title     = {Systems AI: A Declarative Learning Based Programming Perspective},
  author    = {Parisa Kordjamshidi and Dan Roth and Kristian Kersting},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {5464--5471},
  year      = {2018},
  month     = {7},
  doi       = {10.24963/ijcai.2018/771},
  url       = {https://doi.org/10.24963/ijcai.2018/771},
}

@inproceedings{7c79ec9fac8d463fb7ed0ff79189a534,
    title = "Neural Machine Translation advised by Statistical Machine Translation: the case of Farsi-Spanish bilingually low-resource scenario",
    abstract = "In this paper, we propose a sequence-to-sequence NMT model on Farsi-Spanish bilingually low-resource language pair. We apply effective preprocessing steps specific for Farsi language and optimize the model for both translation and transliteration. We also propose a loss function that enhances the word alignment and consequently improves translation quality.",
    keywords = "Natural language processing, Neural machine translation, Statistical machine translation",
    author = "Benyamin Ahmadnia and Parisa Kordjamshidi and Gholamreza Haffari",
    year = "2018",
    doi = "10.1109/ICMLA.2018.00196",
    language = "English",
    isbn = "9781538668061",
    pages = "1209--1213",
    editor = "Wani, {M. Arif} and Mehmed Kantardzic and Moamar Sayed-Mouchaweh and Joao Gama and Edwin Lughofer",
    booktitle = "Proceedings - 17th IEEE International Conference on Machine Learning and Applications",
    publisher = "IEEE, Institute of Electrical and Electronics Engineers",
    address = "United States of America",
    note = "IEEE International Conference on Machine Learning and Applications 2018, ICMLA 2018 ; Conference date: 17-12-2018 Through 20-12-2018",
    url = "https://www.icmla-conference.org/icmla18/",
}


@inproceedings{manzoor-kordjamshidi-2018-anaphora,
    title = "Anaphora Resolution for Improving Spatial Relation Extraction from Text",
    author = "Manzoor, Umar  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the First International Workshop on Spatial Language Understanding",
    month = jun,
    year = "2018",
    address = "New Orleans",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-1407",
    doi = "10.18653/v1/W18-1407",
    pages = "53--62",
    abstract = "Spatial relation extraction from generic text is a challenging problem due to the ambiguity of the prepositions spatial meaning as well as the nesting structure of the spatial descriptions. In this work, we highlight the difficulties that the anaphora can make in the extraction of spatial relations. We use external multi-modal (here visual) resources to find the most probable candidates for resolving the anaphoras that refer to the landmarks of the spatial relations. We then use global inference to decide jointly on resolving the anaphora and extraction of the spatial relations. Our preliminary results show that resolving anaphora improves the state-of-the-art results on spatial relation extraction.",
}

@inproceedings{rahgooy-etal-2018-visually,
    title = "Visually Guided Spatial Relation Extraction from Text",
    author = "Rahgooy, Taher  and
      Manzoor, Umar  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-2124",
    doi = "10.18653/v1/N18-2124",
    pages = "788--794",
    abstract = "Extraction of spatial relations from sentences with complex/nesting relationships is very challenging as often needs resolving inherent semantic ambiguities. We seek help from visual modality to fill the information gap in the text modality and resolve spatial semantic ambiguities. We use various recent vision and language datasets and techniques to train inter-modality alignment models, visual relationship classifiers and propose a novel global inference model to integrate these components into our structured output prediction model for spatial role and relation extraction. Our global inference model enables us to utilize the visual and geometric relationships between objects and improves the state-of-art results of spatial information extraction from text.",
}

% 2017

@misc{kordjamshidi2017relational,
      title={Relational Learning and Feature Extraction by Querying over Heterogeneous Information Networks}, 
      author={Parisa Kordjamshidi and Sameer Singh and Daniel Khashabi and Christos Christodoulopoulos and Mark Summons and Saurabh Sinha and Dan Roth},
      year={2017},
      eprint={1707.07794},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{kordjamshidi-etal-2017-spatial,
    title = "Spatial Language Understanding with Multimodal Graphs using Declarative Learning based Programming",
    author = "Kordjamshidi, Parisa  and
      Rahgooy, Taher  and
      Manzoor, Umar",
    booktitle = "Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-4306",
    doi = "10.18653/v1/W17-4306",
    pages = "33--43",
    abstract = "This work is on a previously formalized semantic evaluation task of spatial role labeling (SpRL) that aims at extraction of formal spatial meaning from text. Here, we report the results of initial efforts towards exploiting visual information in the form of images to help spatial language understanding. We discuss the way of designing new models in the framework of declarative learning-based programming (DeLBP). The DeLBP framework facilitates combining modalities and representing various data in a unified graph. The learning and inference models exploit the structure of the unified graph as well as the global first order domain constraints beyond the data to predict the semantics which forms a structured meaning representation of the spatial context. Continuous representations are used to relate the various elements of the graph originating from different modalities. We improved over the state-of-the-art results on SpRL.",
}

@inproceedings{Kordjamshidi2017CLEF2M,
  title={CLEF 2017: Multimodal Spatial Role Labeling Task Working Notes},
  author={Parisa Kordjamshidi and Taher Rahgooy and Marie-Francine Moens and J. Pustejovsky and Umar Manzoor and Kirk Roberts},
  booktitle={CLEF},
  year={2017}
}

@Inbook{Kordjamshidi2017,
    author="Kordjamshidi, Parisa
    and van Otterlo, Martijn
    and Moens, Marie-Francine",
    editor="Ide, Nancy
    and Pustejovsky, James",
    title="Spatial Role Labeling Annotation Scheme",
    bookTitle="Handbook of Linguistic Annotation",
    year="2017",
    publisher="Springer Netherlands",
    address="Dordrecht",
    pages="1025--1052",
    abstract="Spatial information extraction from natural language is important for many applications including geographical information systems, human computer interaction, providing navigational instructions to robots and visualization or text-to-scene conversion. The main obstacles for corpus-based approaches to perform such extractions have been: (a) the lack of an agreement on a unique semantic model for spatial information; (b) the diversity of formal spatial representation models; (c) the gap between the expressiveness of natural language and formal spatial representation models; and consequently, (d) the lack of annotated data on which machine learning can be employed to learn and extract the spatial relations. These items drive the direction of the contributions on which this chapter is built. In this chapter we introduce a spatial annotation scheme built upon the previous research that supports various aspects of spatial semantics, including static and dynamic spatial relations. The annotation scheme is based on the ideas of holistic spatial semantics as well as qualitative spatial reasoning models. Spatial roles, their relations and indicators along with their multiple formal meaning are tagged using the annotation scheme producing a rich spatial language corpus. The goal of building such a corpus is to produce a resource for training the machine learning methods for mapping the language to formal spatial representation models, and to use it as ground-truth data for evaluation.",
    isbn="978-94-024-0881-2",
    doi="10.1007/978-94-024-0881-2_38",
    url="https://doi.org/10.1007/978-94-024-0881-2_38"
}

% 2016

@inproceedings{kordjamshidi-etal-2016-better,
    title = "Better call {S}aul: Flexible Programming for Learning and Inference in {NLP}",
    author = "Kordjamshidi, Parisa  and
      Khashabi, Daniel  and
      Christodoulopoulos, Christos  and
      Mangipudi, Bhargav  and
      Singh, Sameer  and
      Roth, Dan",
    booktitle = "Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",
    month = dec,
    year = "2016",
    address = "Osaka, Japan",
    publisher = "The COLING 2016 Organizing Committee",
    url = "https://www.aclweb.org/anthology/C16-1285",
    pages = "3030--3040",
    abstract = "We present a novel way for designing complex joint inference and learning models using Saul (Kordjamshidi et al., 2015), a recently-introduced declarative learning-based programming language (DeLBP). We enrich Saul with components that are necessary for a broad range of learning based Natural Language Processing tasks at various levels of granularity. We illustrate these advances using three different, well-known NLP problems, and show how these generic learning and inference modules can directly exploit Saul{'}s graph-based data representation. These properties allow the programmer to easily switch between different model formulations and configurations, and consider various kinds of dependencies and correlations among variables of interest with minimal programming effort. We argue that Saul provides an extremely useful paradigm both for the design of advanced NLP systems and for supporting advanced research in NLP.",
}

@inproceedings{sammons-etal-2016-edison,
    title = "{EDISON}: Feature Extraction for {NLP}, Simplified",
    author = "Sammons, Mark  and
      Christodoulopoulos, Christos  and
      Kordjamshidi, Parisa  and
      Khashabi, Daniel  and
      Srikumar, Vivek  and
      Roth, Dan",
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    month = may,
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://www.aclweb.org/anthology/L16-1645",
    pages = "4085--4092",
    abstract = "When designing Natural Language Processing (NLP) applications that use Machine Learning (ML) techniques, feature extraction becomes a significant part of the development effort, whether developing a new application or attempting to reproduce results reported for existing NLP tasks. We present EDISON, a Java library of feature generation functions used in a suite of state-of-the-art NLP tools, based on a set of generic NLP data structures. These feature extractors populate simple data structures encoding the extracted features, which the package can also serialize to an intuitive JSON file format that can be easily mapped to formats used by ML packages. EDISON can also be used programmatically with JVM-based (Java/Scala) NLP software to provide the feature extractor input. The collection of feature extractors is organised hierarchically and a simple search interface is provided. In this paper we include examples that demonstrate the versatility and ease-of-use of the EDISON feature extraction suite to show that this can significantly reduce the time spent by developers on feature extraction design for NLP systems. The library is publicly hosted at https://github.com/IllinoisCogComp/illinois-cogcomp-nlp/, and we hope that other NLP researchers will contribute to the set of feature extractors. In this way, the community can help simplify reproduction of published results and the integration of ideas from diverse sources when developing new and improved NLP applications.",
}